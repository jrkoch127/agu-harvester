{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79e8863",
   "metadata": {},
   "source": [
    "# AGU Harvester Notebook - Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e177c",
   "metadata": {},
   "source": [
    "Input:\n",
    "- Meeting code\n",
    "- Publication/meeting info further down in Metadata Transformation phase\n",
    "\n",
    "Outfiles:\n",
    "- AGU Abstracts as (agu_results.xlsx)\n",
    "- AGU Author Affiliations/Roles as individual json files in directory \"json_roles\"\n",
    "- Merged data as (agu_final_data.xlsx)\n",
    "- Json file for ingest as (agu_final_data.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys, os, io\n",
    "import argparse\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56a9df",
   "metadata": {},
   "source": [
    "# Get AGU Meeting Abstracts, Author Roles w/ Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0612917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meeting papers -- just change meeting code\n",
    "meetingcode = \"fm21\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "os.chdir('/Users/sao/Documents/Python-Projects/AGU/version2')\n",
    "AGUresults = \"agu_results_v2.xlsx\"\n",
    "if os.path.exists(AGUresults):\n",
    "    paper_results = pd.read_excel(AGUresults)\n",
    "    print('Read',len(paper_results),'papers from file')\n",
    "    \n",
    "    dt = paper_results.explode(\"ChildList_Role\")\n",
    "    roles = [eval(l) for l in dt['ChildList_Role'].to_list()]\n",
    "        # Extract role IDs from data, resulting in list of lists\n",
    "        # The function 'eval' does this: \n",
    "        # Transform\n",
    "        #  [\"['Role/4501570', 'Role/4503884']\",\"['Role/4191734', 'Role/4191863']\"] \n",
    "        # into\n",
    "        # [['Role/4501570', 'Role/4503884'],['Role/4191734', 'Role/4191863']]\n",
    "        # Initially the result is not a proper list of lists, but a list of strings\n",
    "        # that need to be turned into proper lists.\n",
    "        # Now we need to turn the list of lists into just one big list (\"flatten\" the list)\n",
    "    roles = [item for sublist in roles for item in sublist]\n",
    "    roles = list(set(roles))\n",
    "    print('Read',len(roles),'author roles from file')\n",
    "else:\n",
    "    # API Query for Paper data\n",
    "    domain = \"https://agu.confex.com/agu/meetingapi.cgi/Paper\"\n",
    "    AGU_API = domain[:27] + meetingcode + '/' + domain[27:]\n",
    "    data = requests.get(AGU_API).json()\n",
    "    print('Got',len(data),'papers from',meetingcode)\n",
    "\n",
    "    # Extract specified metadata from results\n",
    "    paper_results = pd.json_normalize(data)\n",
    "    paper_results = pd.DataFrame(paper_results)\n",
    "    paper_results = paper_results[[\n",
    "        \"Abstract\",\n",
    "        \"Title\",\n",
    "        \"ChildList_Role\",\n",
    "        \"FinalPaperNumber\",\n",
    "        \"_url\",\n",
    "        \"Withdrawn\",\n",
    "        \"GoodType\"\n",
    "    ]]\n",
    "\n",
    "    # Drop rows where GoodType = Break (these aren't abstracts); Drop withdrawn papers\n",
    "    paper_results = paper_results[paper_results.GoodType != 'Break']\n",
    "    paper_results = paper_results[paper_results.Withdrawn != 'w']\n",
    "    paper_results = paper_results.drop('Withdrawn',axis=1)\n",
    "\n",
    "    # Save excel file of results\n",
    "    paper_results.to_excel(AGUresults, index=False)\n",
    "    print('Refined results and saved',len(paper_results),'papers as \\'agu_results_v2.xlsx\\'')\n",
    "\n",
    "    # Prepare roles list to query API for roles/affiliations\n",
    "    # Role IDs to role_list and deduplicate\n",
    "    dt = paper_results.explode(\"ChildList_Role\")\n",
    "    roles = dt['ChildList_Role'].to_list()\n",
    "    roles = list(set(roles))\n",
    "    roles = [item for item in roles if not(pd.isnull(item)) == True]\n",
    "    print('Extracted', len(roles),'author roles to query')\n",
    "\n",
    "# API Query for Role/Author data\n",
    "domain = \"https://agu.confex.com/agu/meetingapi.cgi/\"\n",
    "AGU_API = domain[:27] + meetingcode + '/' + domain[27:]\n",
    "\n",
    "if os.path.exists(\"json_roles\"):\n",
    "    os.chdir(\"json_roles\")\n",
    "else:\n",
    "    os.mkdir(\"json_roles\")\n",
    "    os.chdir(\"json_roles\")\n",
    "    \n",
    "print('Started role requests at',datetime.datetime.now(),'...\\n')\n",
    "file_counter = 0\n",
    "# for each roleID in the papers list (\"roles\"), if a json file doesn't yet exist,\n",
    "# send an API request for that roleID, and make a new json file, labeling it by ID number\n",
    "for ident in roles:\n",
    "    file = \"{}.json\"\n",
    "    if os.path.exists(file.format(ident[5:])):\n",
    "#         print(\"File\",ident,\"already exists\")\n",
    "        file_counter += 1\n",
    "\n",
    "    else:\n",
    "        AGU_AUTHORS = AGU_API + str(ident)\n",
    "        try:\n",
    "            data = requests.get(AGU_AUTHORS).json()\n",
    "            new_row = {\n",
    "            \"RoleID\":data[\"_url\"],\n",
    "            \"Role\":data[\"Role\"],\n",
    "            \"PaperID\":data[\"Parent_Entry\"],\n",
    "            \"Position\":data[\"Priority\"],\n",
    "            \"FirstName\":data[\"Person_FirstName\"],\n",
    "            \"LastName\":data[\"Person_LastName\"],\n",
    "            \"Affiliation\":data[\"Person_Affiliation\"],\n",
    "            \"City\":data[\"Person_City\"],\n",
    "            \"Country\":data[\"Person_Country\"],\n",
    "            \"ORCID\":data[\"Person_ORCIDiD\"]\n",
    "            }\n",
    "            \n",
    "            with open(file.format(ident[5:]),\"w\") as outfile:\n",
    "                json.dump(new_row, outfile)\n",
    "#             print('Harvest success for',ident)\n",
    "            file_counter += 1\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(\"Harvesting failed for {0} with the following reason: {1}\".format(ident, err))\n",
    "\n",
    "        \n",
    "print('Finished role requests at',datetime.datetime.now())\n",
    "print('Retrieved',file_counter,'author roles \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7237a",
   "metadata": {},
   "source": [
    "## Convert json files to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = \"/Users/sao/Documents/Python-Projects/AGU/version2/json_roles/\"\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "\n",
    "# here I define my pandas Dataframe with the columns I want to get from the json\n",
    "role_results = pd.DataFrame(columns=['RoleID','Role','PaperID','Position','FirstName',\n",
    "                                     'LastName','Affiliation','City','Country','ORCID'])\n",
    "\n",
    "# we need both the json and an index number so use enumerate()\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "\n",
    "        # here you need to know the layout of your json and each json has to have\n",
    "        # the same structure (obviously not the structure I have here)\n",
    "        roleID = json_text['RoleID']\n",
    "        role = json_text['Role']\n",
    "        paperID = json_text['PaperID']\n",
    "        position = json_text['Position']\n",
    "        firstname = json_text['FirstName']\n",
    "        lastname = json_text['LastName']\n",
    "        affiliation = json_text['Affiliation']\n",
    "        city = json_text['City']\n",
    "        country = json_text['Country']\n",
    "        orcid = json_text['ORCID']\n",
    "        \n",
    "        # here I push a list of data into a pandas DataFrame at row given by 'index'\n",
    "        role_results.loc[index] = [roleID, role, paperID, position, firstname, lastname, affiliation, city, country, orcid]                      \n",
    "\n",
    "                            \n",
    "# Save master excel file of role results\n",
    "role_results.to_excel(\"role_results_v2.xlsx\", index=False)\n",
    "print(\"Saved author affiliation results as \\'role_results.xlsx\\'\")\n",
    "                       \n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc088d2",
   "metadata": {},
   "source": [
    "# Metadata Transformation and Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read abstracts and role results from excel\n",
    "paper_results = pd.read_excel(\"/Users/sao/Documents/Python-Projects/AGU/version2/agu_results_v2.xlsx\")\n",
    "aff_results = pd.read_excel(\"/Users/sao/Documents/Python-Projects/AGU/version2/role_results_v2.xlsx\")\n",
    "papers = pd.DataFrame(paper_results)\n",
    "affs = pd.DataFrame(aff_results)\n",
    "\n",
    "# Method to remove HTML tags\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "\n",
    "# Format Abstracts\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].astype(str)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n\\t_x000D_\\n_x000D_\\n':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n_x000D_\\n':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n\\t':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].apply(lambda cw : remove_tags(cw))\n",
    "\n",
    "# Format Titles\n",
    "papers[\"Title\"] = papers[\"Title\"].apply(lambda cw : remove_tags(cw))\n",
    "papers[\"Title\"] = papers[\"Title\"].replace({'_x000D_\\n':''}, regex=True)\n",
    "\n",
    "# Format Publications -- *Change Meeting Info Here* --->\n",
    "papers[\"Pub\"] = \"AGU Fall Meeting 2021, held in New Orleans, LA, 13-17 December 2021, id. \" + papers[\"FinalPaperNumber\"] + \".\"\n",
    "\n",
    "# Format Authors\n",
    "affs[\"Author\"] = affs[\"LastName\"] + \", \" + affs[\"FirstName\"]\n",
    "\n",
    "# Format full affiliations (Aff, city, country, ORCID)\n",
    "affs[\"ORCIDs\"] = str('<ORCID>') + affs[\"ORCID\"] + str('</ORCID>')\n",
    "affs[\"Aff_full\"] = (\n",
    "    affs[\"Affiliation\"] + \", \" + \n",
    "    affs[\"City\"] + \", \" + \n",
    "    affs[\"Country\"] + \" \" + \n",
    "    affs[\"ORCIDs\"]\n",
    ")\n",
    "affs[\"Aff_full\"] = affs[\"Aff_full\"].fillna(\n",
    "    affs[\"Affiliation\"] + \", \" + \n",
    "    affs[\"City\"] + \", \" + \n",
    "    affs[\"Country\"]\n",
    ")\n",
    "\n",
    "# Sort author/affiliation list by Paper, and then Position; Sort paper list by PaperID\n",
    "affs = affs.sort_values(by=['PaperID', 'Position'])\n",
    "papers = papers.sort_values(by=['_url'])\n",
    "\n",
    "# Select needed columns as new dataframes\n",
    "affs_data = affs[['Author','Aff_full','PaperID','Position']]\n",
    "papers_data = papers[['Abstract','Title','Pub','_url']]\n",
    "\n",
    "# Aggregate Authors and Affiliations by PaperID\n",
    "affs_data = affs_data.replace(np.nan,'NA')\n",
    "affs_data = affs_data.groupby([\"PaperID\"]).agg(Authors=(\"Author\", \"; \".join),Aff_full=(\"Aff_full\", \"; \".join))\n",
    "\n",
    "# Merge papers and authors/affils by PaperID\n",
    "papers_data.rename(columns = {'_url':'PaperID'}, inplace = True)\n",
    "merged = pd.merge(papers_data, affs_data, how='left', on='PaperID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns from merged data to take metadata from\n",
    "authors = merged[\"Authors\"].astype(str)\n",
    "affs = merged[\"Aff_full\"].astype(str)\n",
    "abstracts = merged[\"Abstract\"].astype(str)\n",
    "titles = merged[\"Title\"].astype(str)\n",
    "pubs = merged[\"Pub\"].astype(str)\n",
    "paperIDs = merged[\"PaperID\"].astype(str)\n",
    "\n",
    "# Get author names to list\n",
    "authors_list = []\n",
    "for a in authors:\n",
    "    if a != 'NA':\n",
    "        author = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        authors_list.append(author)\n",
    "    else:\n",
    "        authors_list.append('')\n",
    "\n",
    "# Get author affiliations to list\n",
    "affs_list = []\n",
    "for a in affs:\n",
    "    if a != 'nan':\n",
    "        affil = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        affs_list.append(affil)\n",
    "    else:\n",
    "        affs_list.append('')\n",
    "        \n",
    "# Get abstracts to list\n",
    "abs_list = []\n",
    "for a in abstracts:\n",
    "    if a != 'nan':\n",
    "        abstract = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        abstract = abstract.replace(\"\\n\",\"  \")\n",
    "        abs_list.append(abstract)\n",
    "    else:\n",
    "        abs_list.append('')\n",
    "\n",
    "# Get titles to list\n",
    "titles_list = []\n",
    "for t in titles:\n",
    "    if t != 'nan':\n",
    "        title = unicodedata.normalize('NFD', t).encode('ascii', 'ignore').decode()\n",
    "        titles_list.append(title)\n",
    "    else:\n",
    "        titles_list.append('')\n",
    "\n",
    "# Get publications to list\n",
    "pubs_list = []\n",
    "for p in pubs:\n",
    "    if t != 'nan':\n",
    "        pub = unicodedata.normalize('NFD', p).encode('ascii', 'ignore').decode()\n",
    "        pubs_list.append(pub)\n",
    "    else:\n",
    "        pubs_list.append('')\n",
    "\n",
    "# Package metadata as json records\n",
    "records = []\n",
    "records_counter = 0\n",
    "for auths, affs, title, pub, abstract in zip(authors_list, affs_list, titles_list, pubs_list, abs_list):\n",
    "    authors = auths.split(\"; \")\n",
    "    affils = affs.split(\"; \")\n",
    "    records.append({\"authors\":authors,\n",
    "                    \"affiliations\":affils,\n",
    "                    \"pubdate\":\"12/2021\",\n",
    "                    \"title\":title,\n",
    "                    \"publication\":pub,\n",
    "                    \"abstract\":abstract,\n",
    "                    \"source\":\"ADS\"})\n",
    "    records_counter += 1\n",
    "    \n",
    "# Save json file of data\n",
    "with open(\"agu_final_data_v2.json\", 'w') as outfile:\n",
    "    json.dump(records, outfile)\n",
    "print(\"Saved\",records_counter,\"records as agu_final_data_v2.json\")\n",
    "\n",
    "# Save excel file of data\n",
    "agu_final_papers = pd.json_normalize(records)\n",
    "agu_final_papers.to_excel(\"agu_final_data_v2.xlsx\", index=False)\n",
    "print(\"Saved\",records_counter,\"records as agu_final_papers_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b444af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
