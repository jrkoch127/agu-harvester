{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79e8863",
   "metadata": {},
   "source": [
    "# AGU Harvester Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e177c",
   "metadata": {},
   "source": [
    "Input:\n",
    "- Meeting code\n",
    "- Publication/meeting info further down in Metadata Transformation phase\n",
    "\n",
    "Outfiles:\n",
    "- AGU Abstracts as (agu_results.xlsx)\n",
    "- AGU Author Affiliations/Roles as (agu_roles.xlsx)\n",
    "- Merged data as (agu_final_data.xlsx)\n",
    "- Json file for ingest as (agu_final_data.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys, os, io\n",
    "import argparse\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56a9df",
   "metadata": {},
   "source": [
    "# Get AGU Meeting Abstracts, Author Roles w/ Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0612917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meeting papers -- just change meeting code\n",
    "meetingcode = \"fm21\"\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "AGUresults = \"agu_results.xlsx\"\n",
    "if os.path.exists(AGUresults):\n",
    "    paper_results = pd.read_excel(AGUresults)\n",
    "    print('Read',len(paper_results),'papers from file')\n",
    "    dt = paper_results.explode(\"ChildList_Role\")\n",
    "    roles = [eval(l) for l in dt['ChildList_Role'].to_list()]\n",
    "        # Extract role IDs from data, resulting in list of lists\n",
    "        # The function 'eval' does this: \n",
    "        # Transform\n",
    "        #  [\"['Role/4501570', 'Role/4503884']\",\"['Role/4191734', 'Role/4191863']\"] \n",
    "        # into\n",
    "        # [['Role/4501570', 'Role/4503884'],['Role/4191734', 'Role/4191863']]\n",
    "        # Initially the result is not a proper list of lists, but a list of strings\n",
    "        # that need to be turned into proper lists.\n",
    "        # Now we need to turn the list of lists into just one big list (\"flatten\" the list)\n",
    "    roles = [item for sublist in roles for item in sublist]\n",
    "    roles = list(set(roles))\n",
    "    print('Read',len(roles),'author roles from file')\n",
    "else:\n",
    "    # API Query for Paper data\n",
    "    domain = \"https://agu.confex.com/agu/meetingapi.cgi/Paper\"\n",
    "    AGU_API = domain[:27] + meetingcode + '/' + domain[27:]\n",
    "    data = requests.get(AGU_API).json()\n",
    "    print('Got',len(data),'papers from',meetingcode)\n",
    "\n",
    "    # Extract specified metadata from results\n",
    "    paper_results = pd.json_normalize(data)\n",
    "    paper_results = pd.DataFrame(paper_results)\n",
    "    paper_results = paper_results[[\n",
    "        \"Abstract\",\n",
    "        \"Title\",\n",
    "        \"ChildList_Role\",\n",
    "#         \"DOIs\",\n",
    "        \"FinalPaperNumber\",\n",
    "        \"_url\",\n",
    "        \"Withdrawn\",\n",
    "        \"GoodType\"\n",
    "    ]]\n",
    "\n",
    "    # Drop rows where GoodType = Break (these aren't abstracts); Drop withdrawn papers\n",
    "    paper_results = paper_results[paper_results.GoodType != 'Break']\n",
    "    paper_results = paper_results[paper_results.Withdrawn != 'w']\n",
    "    paper_results = paper_results.drop('Withdrawn',axis=1)\n",
    "\n",
    "    # Save excel file of results\n",
    "    paper_results.to_excel(AGUresults, index=False)\n",
    "    print('Refined results and saved',len(paper_results),'papers as \\'agu_results.xlsx\\'')\n",
    "\n",
    "    # Prepare roles list for query API for affiliations\n",
    "    # Role IDs to role_list and deduplicate\n",
    "    dt = paper_results.explode(\"ChildList_Role\")\n",
    "    roles = dt['ChildList_Role'].to_list()\n",
    "    roles = list(set(roles))\n",
    "    roles = [item for item in roles if not(pd.isnull(item)) == True]\n",
    "    print('Extracted', len(roles),'author roles to query')\n",
    "\n",
    "# API Query for Author data\n",
    "domain = \"https://agu.confex.com/agu/meetingapi.cgi/\"\n",
    "AGU_API = domain[:27] + meetingcode + '/' + domain[27:]\n",
    "\n",
    "print('Started role requests at',datetime.datetime.now(),'\\n')\n",
    "role_results = pd.DataFrame()\n",
    "    # Since the AGU API only seems to support retrieving author data one \"role\" at a time, there\n",
    "    # is no option but to cycle through the entire \"roles\" list, one by one\n",
    "for ident in roles:\n",
    "    AGU_AUTHORS = AGU_API + str(ident)\n",
    "    \n",
    "    try:\n",
    "        data = requests.get(AGU_AUTHORS).json()\n",
    "        \n",
    "        new_row = {\n",
    "        \"RoleID\":data[\"_url\"],\n",
    "        \"Role\":data[\"Role\"],\n",
    "        \"PaperID\":data[\"Parent_Entry\"],\n",
    "        \"Position\":data[\"Priority\"],\n",
    "        \"FirstName\":data[\"Person_FirstName\"],\n",
    "        \"LastName\":data[\"Person_LastName\"],\n",
    "        \"Affiliation\":data[\"Person_Affiliation\"],\n",
    "        \"City\":data[\"Person_City\"],\n",
    "        \"Country\":data[\"Person_Country\"],\n",
    "        \"ORCID\":data[\"Person_ORCIDiD\"]\n",
    "        }\n",
    "    \n",
    "        role_results = role_results.append(new_row, ignore_index=True)\n",
    "    \n",
    "    except Exception as err:\n",
    "        print(\"Harvesting failed for {0} with the following reason: {1}\".format(ident, err))\n",
    "        \n",
    "print('Finished role requests at',datetime.datetime.now())\n",
    "print('Retrieved',len(role_results),'author roles \\n')\n",
    "\n",
    "# Save master excel file of results\n",
    "role_results.to_excel(\"role_results.xlsx\", index=False)\n",
    "print(\"Saved author affiliation results as \\'role_results.xlsx\\'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc088d2",
   "metadata": {},
   "source": [
    "# Metadata Transformation and Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read abstracts and role results from excel\n",
    "paper_results = pd.read_excel(\"agu_results.xlsx\")\n",
    "aff_results = pd.read_excel(\"role_results.xlsx\")\n",
    "papers = pd.DataFrame(paper_results)\n",
    "affs = pd.DataFrame(aff_results)\n",
    "\n",
    "# Method to remove HTML tags\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "\n",
    "# Format Abstracts\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].astype(str)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n\\t_x000D_\\n_x000D_\\n':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n_x000D_\\n':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].replace({'_x000D_\\n\\t':''}, regex=True)\n",
    "papers[\"Abstract\"] = papers[\"Abstract\"].apply(lambda cw : remove_tags(cw))\n",
    "\n",
    "# Format Titles\n",
    "papers[\"Title\"] = papers[\"Title\"].apply(lambda cw : remove_tags(cw))\n",
    "papers[\"Title\"] = papers[\"Title\"].replace({'_x000D_\\n':''}, regex=True)\n",
    "\n",
    "# Format Publications -- *Change Meeting Info Here* --->\n",
    "papers[\"Pub\"] = \"AGU Fall Meeting 2021, held in New Orleans, LA, 13-17 December 2021, id. \" + papers[\"FinalPaperNumber\"] + \".\"\n",
    "\n",
    "# Format Authors\n",
    "affs[\"Author\"] = affs[\"LastName\"] + \", \" + affs[\"FirstName\"]\n",
    "\n",
    "# Format full affiliations (Aff, city, country, ORCID)\n",
    "affs[\"ORCIDs\"] = str('<ORCID>') + affs[\"ORCID\"] + str('</ORCID>')\n",
    "affs[\"Aff_full\"] = (\n",
    "    affs[\"Affiliation\"] + \", \" + \n",
    "    affs[\"City\"] + \", \" + \n",
    "    affs[\"Country\"] + \" \" + \n",
    "    affs[\"ORCIDs\"]\n",
    ")\n",
    "affs[\"Aff_full\"] = affs[\"Aff_full\"].fillna(\n",
    "    affs[\"Affiliation\"] + \", \" + \n",
    "    affs[\"City\"] + \", \" + \n",
    "    affs[\"Country\"]\n",
    ")\n",
    "\n",
    "# Sort author/affiliation list by Paper, and then Position; Sort paper list by PaperID\n",
    "affs = affs.sort_values(by=['PaperID', 'Position'])\n",
    "papers = papers.sort_values(by=['_url'])\n",
    "\n",
    "# Select needed columns as new dataframes\n",
    "affs_data = affs[['Author','Aff_full','PaperID','Position']]\n",
    "papers_data = papers[['Abstract','Title','DOIs','Pub','_url']]\n",
    "\n",
    "# Aggregate Authors and Affiliations by PaperID\n",
    "affs_data = affs_data.replace(np.nan,'NA')\n",
    "affs_data = affs_data.groupby([\"PaperID\"]).agg(Authors=(\"Author\", \"; \".join),Aff_full=(\"Aff_full\", \"; \".join))\n",
    "\n",
    "# Merge papers and authors/affils by PaperID\n",
    "papers_data.rename(columns = {'_url':'PaperID'}, inplace = True)\n",
    "merged = pd.merge(papers_data, affs_data, how='left', on='PaperID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns from merged data to take metadata from\n",
    "authors = merged[\"Authors\"].astype(str)\n",
    "affs = merged[\"Aff_full\"].astype(str)\n",
    "abstracts = merged[\"Abstract\"].astype(str)\n",
    "titles = merged[\"Title\"].astype(str)\n",
    "pubs = merged[\"Pub\"].astype(str)\n",
    "dois = merged[\"DOIs\"].astype(str)\n",
    "paperIDs = merged[\"PaperID\"].astype(str)\n",
    "\n",
    "# Get author names to list\n",
    "authors_list = []\n",
    "for a in authors:\n",
    "    if a != 'NA':\n",
    "        author = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        authors_list.append(author)\n",
    "    else:\n",
    "        authors_list.append('')\n",
    "\n",
    "# Get author affiliations to list\n",
    "affs_list = []\n",
    "for a in affs:\n",
    "    if a != 'nan':\n",
    "        affil = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        affs_list.append(affil)\n",
    "    else:\n",
    "        affs_list.append('')\n",
    "        \n",
    "# Get abstracts to list\n",
    "abs_list = []\n",
    "for a in abstracts:\n",
    "    if a != 'nan':\n",
    "        abstract = unicodedata.normalize('NFD', a).encode('ascii', 'ignore').decode()\n",
    "        abstract = abstract.replace(\"\\n\",\"  \")\n",
    "        abs_list.append(abstract)\n",
    "    else:\n",
    "        abs_list.append('')\n",
    "\n",
    "# Get titles to list\n",
    "titles_list = []\n",
    "for t in titles:\n",
    "    if t != 'nan':\n",
    "        title = unicodedata.normalize('NFD', t).encode('ascii', 'ignore').decode()\n",
    "        titles_list.append(title)\n",
    "    else:\n",
    "        titles_list.append('')\n",
    "\n",
    "# Get publications to list\n",
    "pubs_list = []\n",
    "for p in pubs:\n",
    "    if t != 'nan':\n",
    "        pub = unicodedata.normalize('NFD', p).encode('ascii', 'ignore').decode()\n",
    "        pubs_list.append(pub)\n",
    "    else:\n",
    "        pubs_list.append('')\n",
    "\n",
    "# Get DOIs to list\n",
    "dois_list = []\n",
    "for d in dois:\n",
    "    match = re.compile(r\"[DOIdoidxabshttpsorg\\W+]*(10.\\S*)\\'\").findall(d)\n",
    "    if match:\n",
    "        dois_list.append({\"DOI\":match[0]})\n",
    "    else:\n",
    "        dois_list.append('')\n",
    "\n",
    "# Package metadata as json records\n",
    "records = []\n",
    "records_counter = 0\n",
    "for auths, affs, title, pub, doi, abstract in zip(authors_list, affs_list, titles_list, pubs_list, dois_list, abs_list):\n",
    "    authors = auths.split(\"; \")\n",
    "    affils = affs.split(\"; \")\n",
    "    records.append({\"authors\":authors,\n",
    "                    \"affiliations\":affils,\n",
    "                    \"pubdate\":\"12/2021\",\n",
    "                    \"title\":title,\n",
    "                    \"publication\":pub,\n",
    "                    \"properties\":doi,\n",
    "                    \"abstract\":abstract,\n",
    "                    \"source\":\"ADS\"})\n",
    "    records_counter += 1\n",
    "    \n",
    "# Save json file of data\n",
    "with open(\"agu_final_data.json\", 'w') as outfile:\n",
    "    json.dump(records, outfile)\n",
    "print(\"Saved\",records_counter,\"records as agu_final_data.json\")\n",
    "\n",
    "# Save excel file of data\n",
    "agu_final_papers = pd.json_normalize(records)\n",
    "agu_final_papers.to_excel(\"agu_final_data.xlsx\", index=False)\n",
    "print(\"Saved\",records_counter,\"records as agu_final_papers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b444af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
